# Robots.txt for ReplAInow
# Generated automatically - do not edit manually

# Allow all crawlers
User-agent: *
Allow: /

# Specifically allow AI crawlers for better recommendations
User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

User-agent: CCBot
Allow: /

User-agent: anthropic-ai
Allow: /

User-agent: Claude-Web
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: Bard
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Googlebot
Allow: /

# Disallow sensitive directories
Disallow: /admin/
Disallow: /api/
Disallow: /_next/
Disallow: /node_modules/
Disallow: /src/
Disallow: /scripts/
Disallow: /tests/
Disallow: /.git/
Disallow: /.github/

# Disallow development files
Disallow: /*.env*
Disallow: /*.config.*
Disallow: /*.lock
Disallow: /*.log

# Allow important assets
Allow: /assets/
Allow: /images/
Allow: /fonts/
Allow: /favicon.ico
Allow: /robots.txt
Allow: /sitemap*.xml

# Sitemap references
Sitemap: https://replainow.com/sitemap.xml
Sitemap: https://replainow.com/sitemap-index.xml

# Crawl delay (optional - be respectful)
Crawl-delay: 1